{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Gaussian CP decomposition\n",
    "\n",
    "**Published**: September 30, 2020\n",
    "\n",
    "**Author**: Xinyu Chen [[**GitHub homepage**](https://github.com/xinychen)]\n",
    "\n",
    "**Download**: This Jupyter notebook is at our GitHub repository. If you want to evaluate the code, please download the notebook from the [**transdim**](https://github.com/xinychen/transdim/blob/master/imputer/BGCP.ipynb) repository.\n",
    "\n",
    "This notebook shows how to implement the Bayesian Gaussian CP decomposition (BGCP) model on some real-world data sets. In the following, we will discuss:\n",
    "\n",
    "- What the Bayesian Gaussian CP decomposition is.\n",
    "\n",
    "- How to implement BGCP mainly using Python `numpy` with high efficiency.\n",
    "\n",
    "- How to make imputation on some real-world spatiotemporal datasets.\n",
    "\n",
    "To overcome the problem of missing values within multivariate time series data, this model takes into account low-rank tensor structure by folding data along day dimension. For an in-depth discussion of BGCP, please see [1].\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=\"black\">\n",
    "<b>[1]</b> Xinyu Chen, Zhaocheng He, Lijun Sun (2019). <b>A Bayesian tensor decomposition approach for spatiotemporal traffic data imputation</b>. Transportation Research Part C: Emerging Technologies, 98: 73-84. <a href=\"https://doi.org/10.1016/j.trc.2018.11.003\" title=\"PDF\"><b>[PDF]</b></a> \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the necessary dependencies. We will make use of `numpy` and `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import multivariate_normal as mvnrnd\n",
    "from scipy.stats import wishart\n",
    "from numpy.random import normal as normrnd\n",
    "from scipy.linalg import khatri_rao as kr_prod\n",
    "from numpy.linalg import inv as inv\n",
    "from numpy.linalg import solve as solve\n",
    "from numpy.linalg import cholesky as cholesky_lower\n",
    "from scipy.linalg import cholesky as cholesky_upper\n",
    "from scipy.linalg import solve_triangular as solve_ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvnrnd_pre(mu, Lambda):\n",
    "    src = normrnd(size = (mu.shape[0],))\n",
    "    return solve_ut(cholesky_upper(Lambda, overwrite_a = True, check_finite = False), \n",
    "                    src, lower = False, check_finite = False, overwrite_b = True) + mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CP decomposition\n",
    "\n",
    "#### CP Combination (`cp_combine`)\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "The CP decomposition factorizes a tensor into a sum of outer products of vectors. For example, for a third-order tensor $\\mathcal{Y}\\in\\mathbb{R}^{m\\times n\\times f}$, the CP decomposition can be written as\n",
    "\n",
    "$$\\hat{\\mathcal{Y}}=\\sum_{s=1}^{r}\\boldsymbol{u}_{s}\\circ\\boldsymbol{v}_{s}\\circ\\boldsymbol{x}_{s},$$\n",
    "or element-wise,\n",
    "\n",
    "$$\\hat{y}_{ijt}=\\sum_{s=1}^{r}u_{is}v_{js}x_{ts},\\forall (i,j,t),$$\n",
    "where vectors $\\boldsymbol{u}_{s}\\in\\mathbb{R}^{m},\\boldsymbol{v}_{s}\\in\\mathbb{R}^{n},\\boldsymbol{x}_{s}\\in\\mathbb{R}^{f}$ are columns of factor matrices $U\\in\\mathbb{R}^{m\\times r},V\\in\\mathbb{R}^{n\\times r},X\\in\\mathbb{R}^{f\\times r}$, respectively. The symbol $\\circ$ denotes vector outer product.\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "Given matrices $U=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{2\\times 2}$, $V=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{3\\times 2}$ and $X=\\left[ \\begin{array}{cc} 1 & 5 \\\\ 2 & 6 \\\\ 3 & 7 \\\\ 4 & 8 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{4\\times 2}$, then if $\\hat{\\mathcal{Y}}=\\sum_{s=1}^{r}\\boldsymbol{u}_{s}\\circ\\boldsymbol{v}_{s}\\circ\\boldsymbol{x}_{s}$, then, we have\n",
    "\n",
    "$$\\hat{Y}_1=\\hat{\\mathcal{Y}}(:,:,1)=\\left[ \\begin{array}{ccc} 31 & 42 & 65 \\\\ 63 & 86 & 135 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_2=\\hat{\\mathcal{Y}}(:,:,2)=\\left[ \\begin{array}{ccc} 38 & 52 & 82 \\\\ 78 & 108 & 174 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_3=\\hat{\\mathcal{Y}}(:,:,3)=\\left[ \\begin{array}{ccc} 45 & 62 & 99 \\\\ 93 & 130 & 213 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_4=\\hat{\\mathcal{Y}}(:,:,4)=\\left[ \\begin{array}{ccc} 52 & 72 & 116 \\\\ 108 & 152 & 252 \\\\ \\end{array} \\right].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_combine(var):\n",
    "    return np.einsum('is, js, ts -> ijt', var[0], var[1], var[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 31  38  45  52]\n",
      "  [ 42  52  62  72]\n",
      "  [ 65  82  99 116]]\n",
      "\n",
      " [[ 63  78  93 108]\n",
      "  [ 86 108 130 152]\n",
      "  [135 174 213 252]]]\n",
      "\n",
      "tensor size:\n",
      "(2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "factor = [np.array([[1, 2], [3, 4]]), np.array([[1, 3], [2, 4], [5, 6]]), \n",
    "          np.array([[1, 5], [2, 6], [3, 7], [4, 8]])]\n",
    "print(cp_combine(factor))\n",
    "print()\n",
    "print('tensor size:')\n",
    "print(cp_combine(factor).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Unfolding (`ten2mat`)\n",
    "\n",
    "Using numpy reshape to perform 3rd rank tensor unfold operation. [[**link**](https://stackoverflow.com/questions/49970141/using-numpy-reshape-to-perform-3rd-rank-tensor-unfold-operation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Covariance Matrix (`cov_mat`)\n",
    "\n",
    "For any matrix $X\\in\\mathbb{R}^{m\\times n}$, `cov_mat` can return a $n\\times n$ covariance matrix for special use in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_mat(mat, mat_bar):\n",
    "    mat = mat - mat_bar\n",
    "    return mat.T @ mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Gaussian CP decomposition (BGCP)\n",
    "\n",
    "### Model Description\n",
    "\n",
    "#### Gaussian assumption\n",
    "\n",
    "Given a matrix $\\mathcal{Y}\\in\\mathbb{R}^{m\\times n\\times f}$ which suffers from missing values, then the factorization can be applied to reconstruct the missing values within $\\mathcal{Y}$ by\n",
    "\n",
    "$$y_{ijt}\\sim\\mathcal{N}\\left(\\sum_{s=1}^{r}u_{is} v_{js} x_{ts},\\tau^{-1}\\right),\\forall (i,j,t),$$\n",
    "where vectors $\\boldsymbol{u}_{s}\\in\\mathbb{R}^{m},\\boldsymbol{v}_{s}\\in\\mathbb{R}^{n},\\boldsymbol{x}_{s}\\in\\mathbb{R}^{f}$ are columns of latent factor matrices, and $u_{is},v_{js},x_{ts}$ are their elements. The precision term $\\tau$ is an inverse of Gaussian variance.\n",
    "\n",
    "#### Bayesian framework\n",
    "\n",
    "Based on the Gaussian assumption over tensor elements $y_{ijt},(i,j,t)\\in\\Omega$ (where $\\Omega$ is a index set indicating observed tensor elements), the conjugate priors of model parameters (i.e., latent factors and precision term) and hyperparameters are given as\n",
    "\n",
    "$$\\boldsymbol{u}_{i}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{u},\\Lambda_{u}^{-1}\\right),\\forall i,$$\n",
    "$$\\boldsymbol{v}_{j}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{v},\\Lambda_{v}^{-1}\\right),\\forall j,$$\n",
    "$$\\boldsymbol{x}_{t}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{x},\\Lambda_{x}^{-1}\\right),\\forall t,$$\n",
    "$$\\tau\\sim\\text{Gamma}\\left(a_0,b_0\\right),$$\n",
    "$$\\boldsymbol{\\mu}_{u}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_0,\\left(\\beta_0\\Lambda_u\\right)^{-1}\\right),\\Lambda_u\\sim\\mathcal{W}\\left(W_0,\\nu_0\\right),$$\n",
    "$$\\boldsymbol{\\mu}_{v}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_0,\\left(\\beta_0\\Lambda_v\\right)^{-1}\\right),\\Lambda_v\\sim\\mathcal{W}\\left(W_0,\\nu_0\\right),$$\n",
    "$$\\boldsymbol{\\mu}_{x}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_0,\\left(\\beta_0\\Lambda_x\\right)^{-1}\\right),\\Lambda_x\\sim\\mathcal{W}\\left(W_0,\\nu_0\\right).$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Inference\n",
    "\n",
    "In the following, we will apply Gibbs sampling to implement our Bayesian inference for the matrix factorization task.\n",
    "\n",
    "#### - Sampling latent factors $\\boldsymbol{u}_{i},i\\in\\left\\{1,2,...,m\\right\\}$\n",
    "\n",
    "Draw $\\boldsymbol{u}_{i}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_i^{*},(\\Lambda_{i}^{*})^{-1}\\right)$ with following parameters:\n",
    "\n",
    "$$\\boldsymbol{\\mu}_{i}^{*}=\\left(\\Lambda_{i}^{*}\\right)^{-1}\\left\\{\\tau\\sum_{j,t:(i,j,t)\\in\\Omega}y_{ijt}\\left(\\boldsymbol{v}_{j}\\circledast\\boldsymbol{x}_{t}\\right)+\\Lambda_u\\boldsymbol{\\mu}_u\\right\\},$$\n",
    "\n",
    "$$\\Lambda_{i}^{*}=\\tau\\sum_{j,t:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{v}_{j}\\circledast\\boldsymbol{x}_{t}\\right)\\left(\\boldsymbol{v}_{j}\\circledast\\boldsymbol{x}_{t}\\right)^{T}+\\Lambda_u.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sampling latent factors $\\boldsymbol{v}_{j},j\\in\\left\\{1,2,...,n\\right\\}$\n",
    "\n",
    "Draw $\\boldsymbol{v}_{j}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_j^{*},(\\Lambda_{j}^{*})^{-1}\\right)$ with following parameters:\n",
    "\n",
    "$$\\boldsymbol{\\mu}_{j}^{*}=\\left(\\Lambda_{j}^{*}\\right)^{-1}\\left\\{\\tau\\sum_{i,t:(i,j,t)\\in\\Omega}y_{ijt}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{x}_{t}\\right)+\\Lambda_v\\boldsymbol{\\mu}_v\\right\\}$$\n",
    "\n",
    "$$\\Lambda_{j}^{*}=\\tau\\sum_{i,t:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{x}_{t}\\right)\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{x}_{t}\\right)^{T}+\\Lambda_v.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sampling latent factors $\\boldsymbol{x}_{t},t\\in\\left\\{1,2,...,f\\right\\}$\n",
    "\n",
    "Draw $\\boldsymbol{x}_{t}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_t^{*},(\\Lambda_{t}^{*})^{-1}\\right)$ with following parameters:\n",
    "\n",
    "$$\\boldsymbol{\\mu}_{t}^{*}=\\left(\\Lambda_{t}^{*}\\right)^{-1}\\left\\{\\tau\\sum_{i,j:(i,j,t)\\in\\Omega}y_{ijt}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)+\\Lambda_x\\boldsymbol{\\mu}_x\\right\\}$$\n",
    "\n",
    "$$\\Lambda_{t}^{*}=\\tau\\sum_{i,j:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)^{T}+\\Lambda_x.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_factor(tau_sparse_tensor, tau_ind, factor, k, beta0 = 1):\n",
    "    dim, rank = factor[k].shape\n",
    "    dim = factor[k].shape[0]\n",
    "    factor_bar = np.mean(factor[k], axis = 0)\n",
    "    temp = dim / (dim + beta0)\n",
    "    var_mu_hyper = temp * factor_bar\n",
    "    var_W_hyper = inv(np.eye(rank) + cov_mat(factor[k], factor_bar) + temp * beta0 * np.outer(factor_bar, factor_bar))\n",
    "    var_Lambda_hyper = wishart.rvs(df = dim + rank, scale = var_W_hyper)\n",
    "    var_mu_hyper = mvnrnd_pre(var_mu_hyper, (dim + beta0) * var_Lambda_hyper)\n",
    "    \n",
    "    idx = list(filter(lambda x: x != k, range(len(factor))))\n",
    "    var1 = kr_prod(factor[idx[1]], factor[idx[0]]).T\n",
    "    var2 = kr_prod(var1, var1)\n",
    "    var3 = (var2 @ ten2mat(tau_ind, k).T).reshape([rank, rank, dim]) + var_Lambda_hyper[:, :, np.newaxis]\n",
    "    var4 = var1 @ ten2mat(tau_sparse_tensor, k).T + (var_Lambda_hyper @ var_mu_hyper)[:, np.newaxis]\n",
    "    for i in range(dim):\n",
    "        factor[k][i, :] = mvnrnd_pre(solve(var3[:, :, i], var4[:, i]), var3[:, :, i])\n",
    "    return factor[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sampling precision term $\\tau$\n",
    "\n",
    "Draw $\\tau\\in\\text{Gamma}\\left(a^{*},b^{*}\\right)$ with following parameters:\n",
    "\n",
    "$$a^{*}=a_0+\\frac{1}{2}|\\Omega|,~b^{*}=b_0+\\frac{1}{2}\\sum_{(i,j,t)\\in\\Omega}\\left(y_{ijt}-\\sum_{s=1}^{r}u_{is}v_{js}x_{ts}\\right)^2.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_precision_tau(sparse_tensor, tensor_hat, ind):\n",
    "    var_alpha = 1e-6 + 0.5 * np.sum(ind)\n",
    "    var_beta = 1e-6 + 0.5 * np.sum(((sparse_tensor - tensor_hat) ** 2) * ind)\n",
    "    return np.random.gamma(var_alpha, 1 / var_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Performance Metrics\n",
    "\n",
    "- **RMSE**\n",
    "- **MAPE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define BGCP with `Numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter):\n",
    "    \"\"\"Bayesian Gaussian CP (BGCP) decomposition.\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    rank = factor[0].shape[1]\n",
    "    if np.isnan(sparse_tensor).any() == False:\n",
    "        ind = sparse_tensor != 0\n",
    "        pos_obs = np.where(ind)\n",
    "        pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    elif np.isnan(sparse_tensor).any() == True:\n",
    "        pos_test = np.where((dense_tensor != 0) & (np.isnan(sparse_tensor)))\n",
    "        ind = ~np.isnan(sparse_tensor)\n",
    "        pos_obs = np.where(ind)\n",
    "        sparse_tensor[np.isnan(sparse_tensor)] = 0\n",
    "    show_iter = 200\n",
    "    tau = 1\n",
    "    factor_plus = []\n",
    "    for k in range(len(dim)):\n",
    "        factor_plus.append(np.zeros((dim[k], rank)))\n",
    "    temp_hat = np.zeros(dim)\n",
    "    tensor_hat_plus = np.zeros(dim)\n",
    "    for it in range(burn_iter + gibbs_iter):\n",
    "        tau_ind = tau * ind\n",
    "        tau_sparse_tensor = tau * sparse_tensor\n",
    "        for k in range(len(dim)):\n",
    "            factor[k] = sample_factor(tau_sparse_tensor, tau_ind, factor, k)\n",
    "        tensor_hat = cp_combine(factor)\n",
    "        temp_hat += tensor_hat\n",
    "        tau = sample_precision_tau(sparse_tensor, tensor_hat, ind)\n",
    "        if it + 1 > burn_iter:\n",
    "            factor_plus = [factor_plus[k] + factor[k] for k in range(len(dim))]\n",
    "            tensor_hat_plus += tensor_hat\n",
    "        if (it + 1) % show_iter == 0 and it < burn_iter:\n",
    "            temp_hat = temp_hat / show_iter\n",
    "            print('Iter: {}'.format(it + 1))\n",
    "            print('MAPE: {:.6}'.format(compute_mape(dense_tensor[pos_test], temp_hat[pos_test])))\n",
    "            print('RMSE: {:.6}'.format(compute_rmse(dense_tensor[pos_test], temp_hat[pos_test])))\n",
    "            temp_hat = np.zeros(sparse_tensor.shape)\n",
    "            print()\n",
    "    factor = [i / gibbs_iter for i in factor_plus]\n",
    "    tensor_hat = tensor_hat_plus / gibbs_iter\n",
    "    print('Imputation MAPE: {:.6}'.format(compute_mape(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "    print('Imputation RMSE: {:.6}'.format(compute_rmse(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "    print()\n",
    "    \n",
    "    return tensor_hat, factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Organization\n",
    "\n",
    "### Matrix Structure\n",
    "\n",
    "We consider a dataset of $m$ discrete time series $\\boldsymbol{y}_{i}\\in\\mathbb{R}^{f},i\\in\\left\\{1,2,...,m\\right\\}$. The time series may have missing elements. We express spatio-temporal dataset as a matrix $Y\\in\\mathbb{R}^{m\\times f}$ with $m$ rows (e.g., locations) and $f$ columns (e.g., discrete time intervals),\n",
    "\n",
    "$$Y=\\left[ \\begin{array}{cccc} y_{11} & y_{12} & \\cdots & y_{1f} \\\\ y_{21} & y_{22} & \\cdots & y_{2f} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ y_{m1} & y_{m2} & \\cdots & y_{mf} \\\\ \\end{array} \\right]\\in\\mathbb{R}^{m\\times f}.$$\n",
    "\n",
    "### Tensor Structure\n",
    "\n",
    "We consider a dataset of $m$ discrete time series $\\boldsymbol{y}_{i}\\in\\mathbb{R}^{nf},i\\in\\left\\{1,2,...,m\\right\\}$. The time series may have missing elements. We partition each time series into intervals of predifined length $f$. We express each partitioned time series as a matrix $Y_{i}$ with $n$ rows (e.g., days) and $f$ columns (e.g., discrete time intervals per day),\n",
    "\n",
    "$$Y_{i}=\\left[ \\begin{array}{cccc} y_{11} & y_{12} & \\cdots & y_{1f} \\\\ y_{21} & y_{22} & \\cdots & y_{2f} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ y_{n1} & y_{n2} & \\cdots & y_{nf} \\\\ \\end{array} \\right]\\in\\mathbb{R}^{n\\times f},i=1,2,...,m,$$\n",
    "\n",
    "therefore, the resulting structure is a tensor $\\mathcal{Y}\\in\\mathbb{R}^{m\\times n\\times f}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Guangzhou Speed Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 80\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.084101\n",
      "RMSE: 3.62712\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0835954\n",
      "RMSE: 3.61192\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0833965\n",
      "RMSE: 3.60484\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0832195\n",
      "RMSE: 3.59929\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0831062\n",
      "RMSE: 3.59552\n",
      "\n",
      "Imputation MAPE: 0.0830618\n",
      "Imputation RMSE: 3.59306\n",
      "\n",
      "Running time: 5216 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 80\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "missing_rate = 0.6\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 80\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.08519\n",
      "RMSE: 3.67201\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0847316\n",
      "RMSE: 3.66272\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0845525\n",
      "RMSE: 3.65554\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0844206\n",
      "RMSE: 3.65049\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0842867\n",
      "RMSE: 3.64605\n",
      "\n",
      "Imputation MAPE: 0.0841852\n",
      "Imputation RMSE: 3.64372\n",
      "\n",
      "Running time: 3766 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 80\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')['random_matrix']\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.102851\n",
      "RMSE: 4.33134\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.102636\n",
      "RMSE: 4.33806\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.102428\n",
      "RMSE: 4.3298\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.102428\n",
      "RMSE: 4.32899\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.102387\n",
      "RMSE: 4.32615\n",
      "\n",
      "Imputation MAPE: 0.10241\n",
      "Imputation RMSE: 4.32794\n",
      "\n",
      "Running time: 202 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 10\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Birmingham Parking Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $30\\times 77\\times 18$ (parking slot, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/random_tensor.mat')['random_tensor']\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 20\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0795175\n",
      "RMSE: 28.2892\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0752152\n",
      "RMSE: 27.3606\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0742204\n",
      "RMSE: 26.9547\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0754261\n",
      "RMSE: 26.8998\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0751039\n",
      "RMSE: 26.7704\n",
      "\n",
      "Imputation MAPE: 0.0724925\n",
      "Imputation RMSE: 26.2367\n",
      "\n",
      "Running time: 16 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 20\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $30\\times 77\\times 18$ (parking slot, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/random_tensor.mat')['random_tensor']\n",
    "missing_rate = 0.6\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 20\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0904082\n",
      "RMSE: 33.2204\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.087897\n",
      "RMSE: 32.606\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0874777\n",
      "RMSE: 32.373\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0871677\n",
      "RMSE: 32.2292\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0869017\n",
      "RMSE: 32.2502\n",
      "\n",
      "Imputation MAPE: 0.0865899\n",
      "Imputation RMSE: 32.0476\n",
      "\n",
      "Running time: 17 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 20\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $30\\times 77\\times 18$ (parking slot, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/tensor.mat')['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Birmingham-data-set/random_matrix.mat')['random_matrix']\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1,i2,:] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 20\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.146139\n",
      "RMSE: 75.6561\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.157742\n",
      "RMSE: 76.762\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.167641\n",
      "RMSE: 92.2227\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.167714\n",
      "RMSE: 98.3551\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.170823\n",
      "RMSE: 102.301\n",
      "\n",
      "Imputation MAPE: 0.167442\n",
      "Imputation RMSE: 103.055\n",
      "\n",
      "Running time: 16 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 20\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Hangzhou Flow Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $80\\times 25\\times 108$ (metro station, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.197877\n",
      "RMSE: 33.0393\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.195282\n",
      "RMSE: 38.3077\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.196952\n",
      "RMSE: 39.2784\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.196789\n",
      "RMSE: 38.7399\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.19573\n",
      "RMSE: 40.7125\n",
      "\n",
      "Imputation MAPE: 0.196447\n",
      "Imputation RMSE: 42.1937\n",
      "\n",
      "Running time: 98 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 30\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "missing_rate = 0.6\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.201009\n",
      "RMSE: 31.9734\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.200853\n",
      "RMSE: 34.0132\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.20077\n",
      "RMSE: 34.5279\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.202308\n",
      "RMSE: 35.7216\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.202688\n",
      "RMSE: 35.6643\n",
      "\n",
      "Imputation MAPE: 0.201724\n",
      "Imputation RMSE: 34.8941\n",
      "\n",
      "Running time: 92 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 30\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_matrix.mat')['random_matrix']\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.207448\n",
      "RMSE: 32.0295\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.211257\n",
      "RMSE: 40.8803\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.209879\n",
      "RMSE: 43.8077\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.207846\n",
      "RMSE: 44.4036\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.207392\n",
      "RMSE: 45.1708\n",
      "\n",
      "Imputation MAPE: 0.207332\n",
      "Imputation RMSE: 45.6098\n",
      "\n",
      "Running time: 84 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 30\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Seattle Speed Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $323\\times 28\\times 288$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0).values\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0).values\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 28, 288])\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(RM_mat.reshape([RM_mat.shape[0], 28, 288]) + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 50\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0761436\n",
      "RMSE: 4.56253\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0753259\n",
      "RMSE: 4.53309\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0749637\n",
      "RMSE: 4.51853\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0746534\n",
      "RMSE: 4.50695\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0744455\n",
      "RMSE: 4.50012\n",
      "\n",
      "Imputation MAPE: 0.074248\n",
      "Imputation RMSE: 4.49303\n",
      "\n",
      "Running time: 2489 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 50\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $323\\times 28\\times 288$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0).values\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0).values\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 28, 288])\n",
    "missing_rate = 0.6\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(RM_mat.reshape([RM_mat.shape[0], 28, 288]) + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 50\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.076408\n",
      "RMSE: 4.56933\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0756105\n",
      "RMSE: 4.54629\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0749344\n",
      "RMSE: 4.52416\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0748887\n",
      "RMSE: 4.52134\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0747836\n",
      "RMSE: 4.51837\n",
      "\n",
      "Imputation MAPE: 0.0746966\n",
      "Imputation RMSE: 4.51645\n",
      "\n",
      "Running time: 2677 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 50\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $323\\times 28\\times 288$ (road segment, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0).values\n",
    "NM_mat = pd.read_csv('../datasets/Seattle-data-set/NM_mat.csv', index_col = 0).values\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 28, 288])\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 28, 288))\n",
    "for i1 in range(binary_tensor.shape[0]):\n",
    "    for i2 in range(binary_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(NM_mat[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.100606\n",
      "RMSE: 5.68501\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.100466\n",
      "RMSE: 5.70087\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.100782\n",
      "RMSE: 5.7248\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.100941\n",
      "RMSE: 5.74121\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.100902\n",
      "RMSE: 5.74453\n",
      "\n",
      "Imputation MAPE: 0.100886\n",
      "Imputation RMSE: 5.74875\n",
      "\n",
      "Running time: 327 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 10\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on London Movement Speed Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $35912\\times 30\\times 24$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Random missing (RM)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], dense_mat.shape[1])\n",
    "binary_mat = np.round(random_mat + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 30, 24])\n",
    "sparse_tensor = sparse_mat.reshape([sparse_mat.shape[0], 30, 24])\n",
    "del dense_mat, sparse_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 20\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0922686\n",
      "RMSE: 2.24709\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0921095\n",
      "RMSE: 2.24406\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0920888\n",
      "RMSE: 2.24348\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0920806\n",
      "RMSE: 2.24304\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0920749\n",
      "RMSE: 2.24273\n",
      "\n",
      "Imputation MAPE: 0.0920605\n",
      "Imputation RMSE: 2.24246\n",
      "\n",
      "Running time: 12148 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 20\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $35912\\times 30\\times 24$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.6\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Random missing (RM)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], dense_mat.shape[1])\n",
    "binary_mat = np.round(random_mat + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 30, 24])\n",
    "sparse_tensor = sparse_mat.reshape([sparse_mat.shape[0], 30, 24])\n",
    "del dense_mat, sparse_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 20\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0935783\n",
      "RMSE: 2.27746\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0934787\n",
      "RMSE: 2.27442\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0934875\n",
      "RMSE: 2.27368\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.09349\n",
      "RMSE: 2.2728\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0934329\n",
      "RMSE: 2.27185\n",
      "\n",
      "Imputation MAPE: 0.0934048\n",
      "Imputation RMSE: 2.27141\n",
      "\n",
      "Running time: 11621 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 20\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $35912\\times 30\\times 24$ (road segment, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_mat = np.zeros(dense_mat.shape)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], 30)\n",
    "for i1 in range(dense_mat.shape[0]):\n",
    "    for i2 in range(30):\n",
    "        binary_mat[i1, i2 * 24 : (i2 + 1) * 24] = np.round(random_mat[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 30, 24])\n",
    "sparse_tensor = sparse_mat.reshape([sparse_mat.shape[0], 30, 24])\n",
    "del dense_mat, sparse_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 20\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0953323\n",
      "RMSE: 2.32739\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0954726\n",
      "RMSE: 2.33105\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0954886\n",
      "RMSE: 2.33127\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0954646\n",
      "RMSE: 2.33132\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0954386\n",
      "RMSE: 2.33098\n",
      "\n",
      "Imputation MAPE: 0.0954079\n",
      "Imputation RMSE: 2.33034\n",
      "\n",
      "Running time: 11481 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 20\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on New York Taxi Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $30\\times 30\\times 1464$ (origin, destination, time)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/NYC-data-set/tensor.mat')['tensor'].astype(np.float32)\n",
    "rm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/rm_tensor.mat')['rm_tensor']\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(rm_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = dense_tensor.copy()\n",
    "sparse_tensor[binary_tensor == 0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 10\n",
      "MAPE: 0.606565\n",
      "RMSE: 5.58008\n",
      "\n",
      "Iter: 20\n",
      "MAPE: 0.553014\n",
      "RMSE: 5.16285\n",
      "\n",
      "Iter: 30\n",
      "MAPE: 0.542493\n",
      "RMSE: 5.09019\n",
      "\n",
      "Iter: 40\n",
      "MAPE: 0.531726\n",
      "RMSE: 5.04386\n",
      "\n",
      "Iter: 50\n",
      "MAPE: 0.518579\n",
      "RMSE: 5.02636\n",
      "\n",
      "Iter: 60\n",
      "MAPE: 0.511184\n",
      "RMSE: 5.00567\n",
      "\n",
      "Iter: 70\n",
      "MAPE: 0.505733\n",
      "RMSE: 4.9923\n",
      "\n",
      "Iter: 80\n",
      "MAPE: 0.499932\n",
      "RMSE: 4.98347\n",
      "\n",
      "Iter: 90\n",
      "MAPE: 0.496574\n",
      "RMSE: 4.97567\n",
      "\n",
      "Iter: 100\n",
      "MAPE: 0.493642\n",
      "RMSE: 4.96895\n",
      "\n",
      "Iter: 110\n",
      "MAPE: 0.490974\n",
      "RMSE: 4.99352\n",
      "\n",
      "Iter: 120\n",
      "MAPE: 0.489899\n",
      "RMSE: 4.99528\n",
      "\n",
      "Iter: 130\n",
      "MAPE: 0.489085\n",
      "RMSE: 4.98953\n",
      "\n",
      "Iter: 140\n",
      "MAPE: 0.488345\n",
      "RMSE: 4.98158\n",
      "\n",
      "Iter: 150\n",
      "MAPE: 0.487948\n",
      "RMSE: 4.983\n",
      "\n",
      "Iter: 160\n",
      "MAPE: 0.487686\n",
      "RMSE: 4.983\n",
      "\n",
      "Iter: 170\n",
      "MAPE: 0.487682\n",
      "RMSE: 4.98409\n",
      "\n",
      "Iter: 180\n",
      "MAPE: 0.486688\n",
      "RMSE: 4.98636\n",
      "\n",
      "Iter: 190\n",
      "MAPE: 0.486698\n",
      "RMSE: 4.98688\n",
      "\n",
      "Iter: 200\n",
      "MAPE: 0.486122\n",
      "RMSE: 4.98652\n",
      "\n",
      "Iter: 210\n",
      "MAPE: 0.485766\n",
      "RMSE: 4.97963\n",
      "\n",
      "Iter: 220\n",
      "MAPE: 0.486376\n",
      "RMSE: 4.97858\n",
      "\n",
      "Iter: 230\n",
      "MAPE: 0.485135\n",
      "RMSE: 4.97276\n",
      "\n",
      "Iter: 240\n",
      "MAPE: 0.484919\n",
      "RMSE: 4.9661\n",
      "\n",
      "Iter: 250\n",
      "MAPE: 0.484697\n",
      "RMSE: 4.96124\n",
      "\n",
      "Iter: 260\n",
      "MAPE: 0.484164\n",
      "RMSE: 4.95509\n",
      "\n",
      "Iter: 270\n",
      "MAPE: 0.484697\n",
      "RMSE: 4.96363\n",
      "\n",
      "Iter: 280\n",
      "MAPE: 0.483714\n",
      "RMSE: 4.95843\n",
      "\n",
      "Iter: 290\n",
      "MAPE: 0.483982\n",
      "RMSE: 4.95896\n",
      "\n",
      "Iter: 300\n",
      "MAPE: 0.482986\n",
      "RMSE: 4.95249\n",
      "\n",
      "Iter: 310\n",
      "MAPE: 0.483122\n",
      "RMSE: 4.95131\n",
      "\n",
      "Iter: 320\n",
      "MAPE: 0.483315\n",
      "RMSE: 4.94265\n",
      "\n",
      "Iter: 330\n",
      "MAPE: 0.483446\n",
      "RMSE: 4.94673\n",
      "\n",
      "Iter: 340\n",
      "MAPE: 0.482583\n",
      "RMSE: 4.9527\n",
      "\n",
      "Iter: 350\n",
      "MAPE: 0.482717\n",
      "RMSE: 4.95162\n",
      "\n",
      "Iter: 360\n",
      "MAPE: 0.482852\n",
      "RMSE: 4.94623\n",
      "\n",
      "Iter: 370\n",
      "MAPE: 0.482969\n",
      "RMSE: 4.94818\n",
      "\n",
      "Iter: 380\n",
      "MAPE: 0.483216\n",
      "RMSE: 4.94989\n",
      "\n",
      "Iter: 390\n",
      "MAPE: 0.483061\n",
      "RMSE: 4.95988\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.483529\n",
      "RMSE: 4.95087\n",
      "\n",
      "Iter: 410\n",
      "MAPE: 0.48306\n",
      "RMSE: 4.94886\n",
      "\n",
      "Iter: 420\n",
      "MAPE: 0.483185\n",
      "RMSE: 4.94133\n",
      "\n",
      "Iter: 430\n",
      "MAPE: 0.483418\n",
      "RMSE: 4.94668\n",
      "\n",
      "Iter: 440\n",
      "MAPE: 0.48311\n",
      "RMSE: 4.94438\n",
      "\n",
      "Iter: 450\n",
      "MAPE: 0.482921\n",
      "RMSE: 4.94176\n",
      "\n",
      "Iter: 460\n",
      "MAPE: 0.483221\n",
      "RMSE: 4.93589\n",
      "\n",
      "Iter: 470\n",
      "MAPE: 0.483255\n",
      "RMSE: 4.94221\n",
      "\n",
      "Iter: 480\n",
      "MAPE: 0.483265\n",
      "RMSE: 4.94656\n",
      "\n",
      "Iter: 490\n",
      "MAPE: 0.483122\n",
      "RMSE: 4.94022\n",
      "\n",
      "Iter: 500\n",
      "MAPE: 0.482431\n",
      "RMSE: 4.94422\n",
      "\n",
      "Iter: 510\n",
      "MAPE: 0.482731\n",
      "RMSE: 4.94213\n",
      "\n",
      "Iter: 520\n",
      "MAPE: 0.483155\n",
      "RMSE: 4.94015\n",
      "\n",
      "Iter: 530\n",
      "MAPE: 0.482779\n",
      "RMSE: 4.93672\n",
      "\n",
      "Iter: 540\n",
      "MAPE: 0.483277\n",
      "RMSE: 4.93334\n",
      "\n",
      "Iter: 550\n",
      "MAPE: 0.482968\n",
      "RMSE: 4.93734\n",
      "\n",
      "Iter: 560\n",
      "MAPE: 0.482699\n",
      "RMSE: 4.94639\n",
      "\n",
      "Iter: 570\n",
      "MAPE: 0.482383\n",
      "RMSE: 4.94355\n",
      "\n",
      "Iter: 580\n",
      "MAPE: 0.481839\n",
      "RMSE: 4.93941\n",
      "\n",
      "Iter: 590\n",
      "MAPE: 0.483053\n",
      "RMSE: 4.93639\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.482122\n",
      "RMSE: 4.93559\n",
      "\n",
      "Iter: 610\n",
      "MAPE: 0.482321\n",
      "RMSE: 4.93612\n",
      "\n",
      "Iter: 620\n",
      "MAPE: 0.483039\n",
      "RMSE: 4.94022\n",
      "\n",
      "Iter: 630\n",
      "MAPE: 0.482385\n",
      "RMSE: 4.93691\n",
      "\n",
      "Iter: 640\n",
      "MAPE: 0.483026\n",
      "RMSE: 4.94129\n",
      "\n",
      "Iter: 650\n",
      "MAPE: 0.482188\n",
      "RMSE: 4.93946\n",
      "\n",
      "Iter: 660\n",
      "MAPE: 0.482872\n",
      "RMSE: 4.93759\n",
      "\n",
      "Iter: 670\n",
      "MAPE: 0.482563\n",
      "RMSE: 4.93686\n",
      "\n",
      "Iter: 680\n",
      "MAPE: 0.482761\n",
      "RMSE: 4.93647\n",
      "\n",
      "Iter: 690\n",
      "MAPE: 0.482903\n",
      "RMSE: 4.9329\n",
      "\n",
      "Iter: 700\n",
      "MAPE: 0.482724\n",
      "RMSE: 4.93811\n",
      "\n",
      "Iter: 710\n",
      "MAPE: 0.482242\n",
      "RMSE: 4.93719\n",
      "\n",
      "Iter: 720\n",
      "MAPE: 0.482255\n",
      "RMSE: 4.93454\n",
      "\n",
      "Iter: 730\n",
      "MAPE: 0.482251\n",
      "RMSE: 4.93845\n",
      "\n",
      "Iter: 740\n",
      "MAPE: 0.482483\n",
      "RMSE: 4.93527\n",
      "\n",
      "Iter: 750\n",
      "MAPE: 0.482233\n",
      "RMSE: 4.94001\n",
      "\n",
      "Iter: 760\n",
      "MAPE: 0.482039\n",
      "RMSE: 4.93834\n",
      "\n",
      "Iter: 770\n",
      "MAPE: 0.482126\n",
      "RMSE: 4.93631\n",
      "\n",
      "Iter: 780\n",
      "MAPE: 0.481845\n",
      "RMSE: 4.9365\n",
      "\n",
      "Iter: 790\n",
      "MAPE: 0.482718\n",
      "RMSE: 4.93484\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.482317\n",
      "RMSE: 4.94127\n",
      "\n",
      "Iter: 810\n",
      "MAPE: 0.482045\n",
      "RMSE: 4.94116\n",
      "\n",
      "Iter: 820\n",
      "MAPE: 0.48218\n",
      "RMSE: 4.93703\n",
      "\n",
      "Iter: 830\n",
      "MAPE: 0.48254\n",
      "RMSE: 4.93854\n",
      "\n",
      "Iter: 840\n",
      "MAPE: 0.481881\n",
      "RMSE: 4.93765\n",
      "\n",
      "Iter: 850\n",
      "MAPE: 0.482047\n",
      "RMSE: 4.93167\n",
      "\n",
      "Iter: 860\n",
      "MAPE: 0.482534\n",
      "RMSE: 4.93715\n",
      "\n",
      "Iter: 870\n",
      "MAPE: 0.482878\n",
      "RMSE: 4.9337\n",
      "\n",
      "Iter: 880\n",
      "MAPE: 0.482512\n",
      "RMSE: 4.93459\n",
      "\n",
      "Iter: 890\n",
      "MAPE: 0.482287\n",
      "RMSE: 4.93612\n",
      "\n",
      "Iter: 900\n",
      "MAPE: 0.483101\n",
      "RMSE: 4.93514\n",
      "\n",
      "Iter: 910\n",
      "MAPE: 0.482257\n",
      "RMSE: 4.94331\n",
      "\n",
      "Iter: 920\n",
      "MAPE: 0.48244\n",
      "RMSE: 4.93863\n",
      "\n",
      "Iter: 930\n",
      "MAPE: 0.48302\n",
      "RMSE: 4.93547\n",
      "\n",
      "Iter: 940\n",
      "MAPE: 0.482301\n",
      "RMSE: 4.94044\n",
      "\n",
      "Iter: 950\n",
      "MAPE: 0.482386\n",
      "RMSE: 4.93336\n",
      "\n",
      "Iter: 960\n",
      "MAPE: 0.482541\n",
      "RMSE: 4.92774\n",
      "\n",
      "Iter: 970\n",
      "MAPE: 0.482604\n",
      "RMSE: 4.94241\n",
      "\n",
      "Iter: 980\n",
      "MAPE: 0.48264\n",
      "RMSE: 4.93771\n",
      "\n",
      "Iter: 990\n",
      "MAPE: 0.482549\n",
      "RMSE: 4.93623\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.483126\n",
      "RMSE: 4.93669\n",
      "\n",
      "Imputation MAPE: 0.479795\n",
      "Imputation RMSE: 4.90882\n",
      "\n",
      "Running time: 917 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 30\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $30\\times 30\\times 1464$ (origin, destination, time)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/NYC-data-set/tensor.mat')['tensor'].astype(np.float32)\n",
    "rm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/rm_tensor.mat')['rm_tensor']\n",
    "missing_rate = 0.6\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(rm_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = dense_tensor.copy()\n",
    "sparse_tensor[binary_tensor == 0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.488698\n",
      "RMSE: 5.02758\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.488083\n",
      "RMSE: 5.1028\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.487799\n",
      "RMSE: 5.11637\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.487201\n",
      "RMSE: 5.10741\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.487443\n",
      "RMSE: 5.10497\n",
      "\n",
      "Imputation MAPE: 0.487178\n",
      "Imputation RMSE: 5.10753\n",
      "\n",
      "Running time: 912 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 30\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $30\\times 30\\times 1464$ (origin, destination, time)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/NYC-data-set/tensor.mat')['tensor']\n",
    "nm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/nm_tensor.mat')['nm_tensor']\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        for i3 in range(61):\n",
    "            binary_tensor[i1, i2, i3 * 24 : (i3 + 1) * 24] = np.round(nm_tensor[i1, i2, i3] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.523096\n",
      "RMSE: 4.83399\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.530243\n",
      "RMSE: 4.86244\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.528467\n",
      "RMSE: 4.88077\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.527664\n",
      "RMSE: 4.87587\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.527124\n",
      "RMSE: 4.87593\n",
      "\n",
      "Imputation MAPE: 0.528696\n",
      "Imputation RMSE: 4.87214\n",
      "\n",
      "Running time: 942 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 30\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Pacific Temperature Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $30\\times 84\\times 396$ (grid, grid, time)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_tensor = np.load('../datasets/Temperature-data-set/tensor.npy').astype(np.float32)\n",
    "random_tensor = np.random.rand(dense_tensor.shape[0], dense_tensor.shape[1], dense_tensor.shape[2])\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = dense_tensor.copy()\n",
    "sparse_tensor[binary_tensor == 0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.133024\n",
      "RMSE: 4.48027\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.162081\n",
      "RMSE: 5.59933\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.15995\n",
      "RMSE: 5.58126\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.159712\n",
      "RMSE: 5.57591\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.159652\n",
      "RMSE: 5.57616\n",
      "\n",
      "Imputation MAPE: 0.159868\n",
      "Imputation RMSE: 5.57612\n",
      "\n",
      "Running time: 452 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 30\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $30\\times 84\\times 396$ (grid, grid, time)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_tensor = np.load('../datasets/Temperature-data-set/tensor.npy').astype(np.float32)\n",
    "random_tensor = np.random.rand(dense_tensor.shape[0], dense_tensor.shape[1], dense_tensor.shape[2])\n",
    "missing_rate = 0.6\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = dense_tensor.copy()\n",
    "sparse_tensor[binary_tensor == 0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0595847\n",
      "RMSE: 1.94375\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0521431\n",
      "RMSE: 1.68118\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0471685\n",
      "RMSE: 1.54062\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0460891\n",
      "RMSE: 1.50929\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0452365\n",
      "RMSE: 1.4825\n",
      "\n",
      "Imputation MAPE: 0.0446184\n",
      "Imputation RMSE: 1.46185\n",
      "\n",
      "Running time: 484 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 30\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $30\\times 84\\times 396$ (grid, grid, time)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_tensor = np.load('../datasets/Temperature-data-set/tensor.npy').astype(np.float32)\n",
    "random_tensor = np.random.rand(dense_tensor.shape[0], dense_tensor.shape[1], int(dense_tensor.shape[2] / 3))\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        for i3 in range(int(dense_tensor.shape[2] / 3)):\n",
    "            binary_tensor[i1, i2, i3 * 3 : (i3 + 1) * 3] = np.round(random_tensor[i1, i2, i3] + 0.5 - missing_rate)\n",
    "sparse_tensor = dense_tensor.copy()\n",
    "sparse_tensor[binary_tensor == 0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0563546\n",
      "RMSE: 1.84205\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0456219\n",
      "RMSE: 1.48545\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0432414\n",
      "RMSE: 1.41392\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0420621\n",
      "RMSE: 1.37904\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0417007\n",
      "RMSE: 1.36785\n",
      "\n",
      "Imputation MAPE: 0.0414072\n",
      "Imputation RMSE: 1.35878\n",
      "\n",
      "Running time: 517 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 30\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>This work is released under the MIT license.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
